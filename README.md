# DiForest

Open-source experimental datasets from iPhone edge data and synthetic datasets from publication "Discretized-Isolation Forest: Memory- & Compute-Efficient Unsupervised Anomaly Detection for Resource-Constrained Internet-of-Things Edge Devices", IEEE IOTJ 2024. The abstract of the publication and descriptions of the datasets are provided below.

**Reference:** E. Ortega, F. Su, R. Chattopadhyay, K. Chakrabarty, "Discretized-Isolation Forest: Memory- & Compute-Efficient Unsupervised Anomaly Detection for Resource-Constrained Internet-of-Things Edge Devices" 2024 IEEE Internet-of-Things Journal 

**Abstract:** Memory and compute constraints make anomaly detection model training infeasible on Internet-of-Things (IoT) resource-limited edge devices. Many solutions train anomaly detection models (e.g., deep neural networks or DNN) on the cloud and deploy them on IoT edge devices for inferencing. However, cloud-based training does not address overall communication latency and potential data leakage. Moreover, because anomalies rarely occur, using labels to define anomalies is impractical. Hence, supervised learning mechanisms are unsuitable for anomaly detection. There is a need for effective unsupervised anomaly detection for resource-constrained edge devices. We present the Discretized Isolation Forest to address memory- and compute-efficient unsupervised anomaly detection for resource-constrained edge devices. We also present a discretization function, based on information entropy, to inform the growth of the Isolation Forest ensemble to create the Discretized Isolation Forest. The Discretized Isolation Forest reduces the training time (memory usage) of the original Isolation Forest by 79.38× (166.66×). We test the Discretized Isolation Forest against general anomaly detection benchmarks and edge-anomaly detection benchmarks. The edge-anomaly detection benchmarks were curated from the built-in iPhone edge sensors. Across all edge-sensor anomaly detection datasets and against all other considered models, the Discretized Isolation resulted in the lowest training time, lowest memory usage, preserved anomaly detection performance, and highest inference speeds. In addition, across all general anomaly detection benchmarks and against all considered models, Discretized Isolation Forest incurs lower training time and memory usage while retaining competitive inferencing execution time and anomaly detection performance. 
